{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.183jj.com/htm/piclist9/1.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/2.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/3.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/4.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/5.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/6.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/7.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/8.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/9.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/10.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/11.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/12.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/13.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/14.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/15.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/16.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/17.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/18.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/19.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/20.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/21.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/22.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/23.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/24.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/25.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/26.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/27.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/28.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/29.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/30.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/31.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/32.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/33.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/34.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/35.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/36.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/37.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/38.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/39.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/40.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/41.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/42.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/43.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/44.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/45.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/46.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/47.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/48.htm\n",
      "\n",
      "[]\n",
      "http://www.183jj.com/htm/piclist9/49.htm\n",
      "\n",
      "[]\n",
      "所有爬取已完成\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "\n",
    "def getHTMLText(url):\n",
    "    \"\"\"获得原始网页代码\"\"\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        r.encoding = 'utf-8'\n",
    "        return r.text\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def save_picture(picture_url, fpath):\n",
    "    try:\n",
    "        picture = requests.get(picture_url)\n",
    "        picture.raise_for_status()\n",
    "        with open(fpath, 'wb') as f:\n",
    "            f.write(picture.content)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def get_picture_name(url):\n",
    "    \"\"\"从图片链接中获取图片名称\"\"\"\n",
    "    pic_name = url.split('/')[-1]\n",
    "    return pic_name\n",
    "\n",
    "\n",
    "def get_picture(html,start_fpath):\n",
    "    \"\"\"从原始网页中获取图片\"\"\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    if soup:\n",
    "        #获取存放改网页所有图片的文件夹名称,并新建该目录\n",
    "        folder_name = soup.find('title').text.split(' ')[0]\n",
    "        print(\"当前处理页面：\",folder_name)\n",
    "        folder_path = start_fpath + '/' + folder_name\n",
    "        folder_isExists = os.path.exists(folder_path)\n",
    "        if not folder_isExists:\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        #查找图片相关的网页源代码段，并将其中网页链接的相关标签存入列表\n",
    "        pic_info = soup.find('div', attrs={'class': 'pics'})\n",
    "        pic_list = pic_info.find_all('img')\n",
    "        \n",
    "        \n",
    "        #将图片的链接存入列表\n",
    "        pic_url_list = []\n",
    "        for i in range(len(pic_list)):\n",
    "            pic_url_list.append(pic_list[i].attrs['src'])\n",
    "\n",
    "        #遍历图片链接的列表，存储图片到本地目录\n",
    "        for i in range(len(pic_url_list)):\n",
    "            pic_name = get_picture_name(pic_url_list[i])\n",
    "            fpath = start_fpath + '/' + folder_name + '/' + pic_name\n",
    "            picture_isExists = os.path.exists(fpath)\n",
    "            if not picture_isExists:\n",
    "                save_picture(pic_url_list[i], fpath)\n",
    "            print(\"共%d张照片，已爬取%d张照片，当前进度：%.2f%%\" % (len(pic_url_list), (i + 1), float(i + 1) / len(pic_url_list) * 100))\n",
    "        print(\"-\"*60)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "def get_url_list(list_url, start_url):\n",
    "    \"\"\"从导航页中得到包含不同组图的网页链接列表\"\"\"\n",
    "    original_html = getHTMLText(list_url)\n",
    "    #soup = BeautifulSoup(original_html, 'html.parser')\n",
    "    #url_info=soup.find('li')\n",
    "    print(\"网页\",original_html)\n",
    "    original_list = re.findall(r'href=\\\"/htm/pic9/.*?htm', original_html)\n",
    "    url_list=[]\n",
    "    for i in range(len(original_list)):\n",
    "        last_url = original_list[i].split('/')[-1]\n",
    "        url = start_url + last_url\n",
    "        url_list.append(url)\n",
    "    return url_list\n",
    "        \n",
    "\n",
    "\n",
    "def main():\n",
    "    #PC用路径\n",
    "    #start_fpath = 'F:/Craw Picutre/偷拍自拍'\n",
    "    #NAS用路径\n",
    "    start_fpath = '/volume1/爬虫相关/Craw Picutre/偷拍自拍'\n",
    "    start_url = 'http://www.183jj.com/htm/pic9/'\n",
    "    start_list_url = 'http://www.183jj.com/htm/piclist9/'\n",
    "    #url = start_url + '120672' + '.htm'\n",
    "    #html = getHTMLText(url)\n",
    "    for i in range(1, 50):\n",
    "        list_url = start_list_url + str(i) + '.htm'\n",
    "        print(list_url)\n",
    "        url_list=get_url_list(list_url, start_url)\n",
    "        print(url_list)\n",
    "        for j in range(len(url_list)):\n",
    "            html=getHTMLText(url_list[j])\n",
    "            get_picture(html, start_fpath)\n",
    "    print(\"所有爬取已完成\")\n",
    "    os.system(\"pause\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
