{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=61.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=62.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=63.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=64.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=65.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=66.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=67.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=68.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=69.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=610.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=611.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=612.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=613.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=614.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=615.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=616.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=617.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=618.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=619.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=620.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=621.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=622.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=623.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=624.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=625.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=626.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=627.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=628.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=629.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=630.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=631.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=632.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=633.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=634.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=635.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=636.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=637.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=638.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=639.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=640.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=641.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=642.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=643.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=644.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=645.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=646.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=647.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=648.htm\n",
      "网页 \n",
      "[]\n",
      "https://www.a8e0e744fa9b81a7.com/piclist.x?classid=649.htm\n",
      "网页 \n",
      "[]\n",
      "所有爬取已完成\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "\n",
    "def getHTMLText(url):\n",
    "    \"\"\"获得原始网页代码\"\"\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        r.encoding = 'utf-8'\n",
    "        return r.text\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def save_picture(picture_url, fpath):\n",
    "    try:\n",
    "        picture = requests.get(picture_url)\n",
    "        picture.raise_for_status()\n",
    "        with open(fpath, 'wb') as f:\n",
    "            f.write(picture.content)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def get_picture_name(url):\n",
    "    \"\"\"从图片链接中获取图片名称\"\"\"\n",
    "    pic_name = url.split('/')[-1]\n",
    "    return pic_name\n",
    "\n",
    "\n",
    "def get_picture(html,start_fpath):\n",
    "    \"\"\"从原始网页中获取图片\"\"\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    if soup:\n",
    "        #获取存放改网页所有图片的文件夹名称,并新建该目录\n",
    "        folder_name = soup.find('title').text.split(' ')[0]\n",
    "        print(\"当前处理页面：\",folder_name)\n",
    "        folder_path = start_fpath + '/' + folder_name\n",
    "        folder_isExists = os.path.exists(folder_path)\n",
    "        if not folder_isExists:\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        #查找图片相关的网页源代码段，并将其中网页链接的相关标签存入列表\n",
    "        pic_info = soup.find('div', attrs={'class': 'pics'})\n",
    "        pic_list = pic_info.find_all('img')\n",
    "        \n",
    "        \n",
    "        #将图片的链接存入列表\n",
    "        pic_url_list = []\n",
    "        for i in range(len(pic_list)):\n",
    "            pic_url_list.append(pic_list[i].attrs['src'])\n",
    "\n",
    "        #遍历图片链接的列表，存储图片到本地目录\n",
    "        for i in range(len(pic_url_list)):\n",
    "            pic_name = get_picture_name(pic_url_list[i])\n",
    "            fpath = start_fpath + '/' + folder_name + '/' + pic_name\n",
    "            picture_isExists = os.path.exists(fpath)\n",
    "            if not picture_isExists:\n",
    "                save_picture(pic_url_list[i], fpath)\n",
    "            print(\"共%d张照片，已爬取%d张照片，当前进度：%.2f%%\" % (len(pic_url_list), (i + 1), float(i + 1) / len(pic_url_list) * 100))\n",
    "        print(\"-\"*60)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "def get_url_list(list_url, start_url):\n",
    "    \"\"\"从导航页中得到包含不同组图的网页链接列表\"\"\"\n",
    "    original_html = getHTMLText(list_url)\n",
    "    #soup = BeautifulSoup(original_html, 'html.parser')\n",
    "    #url_info=soup.find('li')\n",
    "    print(\"网页\",original_html)\n",
    "    original_list = re.findall(r'href=\\\"/htm/pic9/.*?htm', original_html)\n",
    "    url_list=[]\n",
    "    for i in range(len(original_list)):\n",
    "        last_url = original_list[i].split('/')[-1]\n",
    "        url = start_url + last_url\n",
    "        url_list.append(url)\n",
    "    return url_list\n",
    "        \n",
    "\n",
    "\n",
    "def main():\n",
    "    #PC用路径\n",
    "    #start_fpath = 'F:/Craw Picutre/偷拍自拍'\n",
    "    #NAS用路径\n",
    "    start_fpath = '/volume1/爬虫相关/Craw Picutre/偷拍自拍'\n",
    "    start_url = 'https://www.a8e0e744fa9b81a7.com/piclist.x?classid=6'\n",
    "    start_list_url = 'https://www.a8e0e744fa9b81a7.com/piclist.x?classid=6'\n",
    "    #url = start_url + '120672' + '.htm'\n",
    "    #html = getHTMLText(url)\n",
    "    for i in range(1, 50):\n",
    "        list_url = start_list_url + str(i) + '.htm'\n",
    "        print(list_url)\n",
    "        url_list=get_url_list(list_url, start_url)\n",
    "        print(url_list)\n",
    "        for j in range(len(url_list)):\n",
    "            html=getHTMLText(url_list[j])\n",
    "            get_picture(html, start_fpath)\n",
    "    print(\"所有爬取已完成\")\n",
    "    os.system(\"pause\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
